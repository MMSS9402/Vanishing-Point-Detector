{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmuvcl/anaconda3/envs/cuti/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import argparse\n",
    "from datetime import date\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datasets\n",
    "import util.misc as utils\n",
    "from datasets import build_matterport_dataset\n",
    "from models import build_model\n",
    "from config import cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"jet\")\n",
    "norm = mpl.colors.Normalize(vmin=0.0, vmax=1.0)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(x):\n",
    "    return sm.to_rgba(x)\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Set gptran', add_help=False)\n",
    "    parser.add_argument('--config-file', \n",
    "                        metavar=\"FILE\",\n",
    "                        help=\"path to config file\",\n",
    "                        type=str,\n",
    "                        default='/home/kmuvcl/source/CTRL-C/config-files/ctrl-c.yaml')\n",
    "    parser.add_argument(\"--opts\",\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=None,\n",
    "                        nargs=argparse.REMAINDER\n",
    "                        )\n",
    "    return parser\n",
    "\n",
    "def compute_vp_err(vp1, vp2, dim=-1):\n",
    "    cos_sim = F.cosine_similarity(vp1, vp2, dim=dim).abs()\n",
    "    cos_sim = np.clip(cos_sim.item(), 0.0, 1.0)    \n",
    "    return np.degrees(np.arccos(cos_sim))\n",
    "\n",
    "def compute_hl_np(hl, sz, eps=1e-6):\n",
    "    (a,b,c) = hl\n",
    "    if b < 0:\n",
    "        a, b, c = -a, -b, -c\n",
    "    b = np.maximum(b, eps)\n",
    "    \n",
    "    left = np.array([-1.0, (a - c)/b])        \n",
    "    right = np.array([1.0, (-a - c)/b])\n",
    "\n",
    "    # scale back to original image    \n",
    "    scale = sz[1]/2\n",
    "    left = scale*left\n",
    "    right = scale*right\n",
    "    return [np.squeeze(left), np.squeeze(right)]\n",
    "\n",
    "def compute_up_vector(zvp, fovy, eps=1e-7):\n",
    "    # image size 2 (-1~1)\n",
    "    focal = 1.0/np.tan(fovy/2.0)\n",
    "    \n",
    "    if zvp[2] < 0:\n",
    "        zvp = -zvp\n",
    "    zvp = zvp / np.maximum(zvp[2], eps)\n",
    "    zvp[2] = focal\n",
    "    return normalize_safe_np(zvp)\n",
    "\n",
    "def decompose_up_vector(v):\n",
    "    pitch = np.arcsin(v[2])\n",
    "    roll = np.arctan(-v[0]/v[1])\n",
    "    return pitch, roll\n",
    "\n",
    "def cosine_similarity(v1, v2, eps=1e-7):\n",
    "    v1 = v1 / np.maximum(LA.norm(v1), eps)\n",
    "    v2 = v2 / np.maximum(LA.norm(v2), eps)\n",
    "    return np.sum(v1*v2)\n",
    "\n",
    "def normalize_safe_np(v, eps=1e-7):\n",
    "    return v/np.maximum(LA.norm(v), eps)\n",
    "\n",
    "def compute_up_vector_error(pred_zvp, pred_fovy, target_up_vector):\n",
    "    pred_up_vector = compute_up_vector(pred_zvp, pred_fovy)\n",
    "    cos_sim = cosine_similarity(target_up_vector, pred_up_vector)\n",
    "\n",
    "    target_pitch, target_roll = decompose_up_vector(target_up_vector)\n",
    "\n",
    "    if cos_sim < 0:\n",
    "        pred_pitch, pred_roll = decompose_up_vector(-pred_up_vector)\n",
    "    else:\n",
    "        pred_pitch, pred_roll = decompose_up_vector(pred_up_vector)\n",
    "\n",
    "    err_angle = np.degrees(np.arccos(np.abs(cos_sim)))\n",
    "    err_pitch = np.degrees(np.abs(pred_pitch - target_pitch))\n",
    "    err_roll = np.degrees(np.abs(pred_roll - target_roll))\n",
    "    return err_angle, err_pitch, err_roll\n",
    "\n",
    "def compute_fovy_error(pred_fovy, target_fovy):\n",
    "    pred_fovy = np.degrees(pred_fovy)\n",
    "    target_fovy = np.degrees(target_fovy)\n",
    "    err_fovy = np.abs(pred_fovy - target_fovy)\n",
    "    return err_fovy.item()\n",
    "\n",
    "def compute_horizon_error(pred_hl, target_hl, img_sz):\n",
    "    target_hl_pts = compute_hl_np(target_hl, img_sz)\n",
    "    pred_hl_pts = compute_hl_np(pred_hl, img_sz)\n",
    "    err_hl = np.maximum(np.abs(target_hl_pts[0][1] - pred_hl_pts[0][1]),\n",
    "                        np.abs(target_hl_pts[1][1] - pred_hl_pts[1][1]))\n",
    "    err_hl /= img_sz[0] # height\n",
    "    return err_hl\n",
    "    \n",
    "def draw_attention(img, weights, cmap, savepath):\n",
    "    extent = [-1, 1, 1, -1]\n",
    "    num_layer = len(weights)\n",
    "    plt.figure(figsize=(num_layer*3,3))\n",
    "    for idx_l in range(num_layer):                    \n",
    "        plt.subplot(1, num_layer, idx_l + 1)\n",
    "        plt.imshow(img, extent=extent)\n",
    "        plt.imshow(weights[idx_l], cmap=cmap, alpha=0.3, extent=extent)\n",
    "        plt.axis('off')\n",
    "    plt.savefig(savepath, pad_inches=0, bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "\n",
    "def draw_attention_segs(img, weights, segs, cmap, savepath):\n",
    "    num_layer = len(weights)\n",
    "    num_segs = len(segs)\n",
    "    plt.figure(figsize=(num_layer*3,3))\n",
    "    for idx_l in range(num_layer):                    \n",
    "        plt.subplot(1, num_layer, idx_l + 1)\n",
    "        plt.imshow(img, extent=[-1, 1, 1, -1])                 \n",
    "        ws = weights[idx_l]\n",
    "        ws = (ws - ws.min())/(ws.max() - ws.min())\n",
    "        for idx_s in range(num_segs):\n",
    "            plt.plot((segs[idx_s,0], segs[idx_s,2]), \n",
    "                     (segs[idx_s,1], segs[idx_s,3]), c=cmap(ws[idx_s]))\n",
    "        plt.axis('off')\n",
    "    plt.savefig(savepath, pad_inches=0, bbox_inches='tight')\n",
    "    plt.close('all')    \n",
    "    \n",
    "def to_device(data, device):\n",
    "    if type(data) == dict:\n",
    "        return {k: v.to(device) for k, v in data.items()}\n",
    "    return [{k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "             for k, v in t.items()} for t in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(cfg.DEVICE)\n",
    "model, _ = build_model(cfg)\n",
    "model.to(device)\n",
    "\n",
    "dataset_test = build_matterport_dataset(image_set='train', cfg=cfg)\n",
    "sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
    "data_loader_test = DataLoader(dataset_test, 1, sampler=sampler_test,\n",
    "                                drop_last=False, \n",
    "                                collate_fn=utils.collate_fn, \n",
    "                                num_workers=2)\n",
    "\n",
    "output_dir = Path(cfg.OUTPUT_DIR)\n",
    "\n",
    "checkpoint = torch.load('/home/kmuvcl/source/CTRL-C/line_embed/checkpoint0099.pth', map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model = model.eval()\n",
    "\n",
    "# initlaize for visualization\n",
    "name = f'gsv_test_{date.today()}'\n",
    "if cfg.TEST.DISPLAY:\n",
    "    fig_output_dir = osp.join(output_dir,'{}'.format(name))\n",
    "    os.makedirs(fig_output_dir, exist_ok=True)\n",
    "\n",
    "dict = {'vp_dot_product':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17222 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m samples \u001b[39m=\u001b[39m samples\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(extra_samples))\n\u001b[0;32m----> 5\u001b[0m extra_samples \u001b[39m=\u001b[39m to_device(extra_samples, device)\n\u001b[1;32m      6\u001b[0m outputs, extra_info \u001b[39m=\u001b[39m model(samples, extra_samples)\n\u001b[1;32m      7\u001b[0m img \u001b[39m=\u001b[39m targets[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39morg_img\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[6], line 122\u001b[0m, in \u001b[0;36mto_device\u001b[0;34m(data, device)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(data) \u001b[39m==\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m {k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m v\n\u001b[1;32m    123\u001b[0m          \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m data]\n",
      "Cell \u001b[0;32mIn[6], line 123\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(data) \u001b[39m==\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m {k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m v\n\u001b[0;32m--> 123\u001b[0m          \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39;49mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m data]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "for i, (samples, extra_samples, targets) in enumerate(tqdm(data_loader_test)):\n",
    "        with torch.no_grad():\n",
    "            samples = samples.to(device)\n",
    "            print(type(extra_samples))\n",
    "            extra_samples = to_device(extra_samples, device)\n",
    "            outputs, extra_info = model(samples, extra_samples)\n",
    "            img = targets[0]['org_img']\n",
    "        \n",
    "            pred_vp1 = outputs['pred_vp1'].to('cpu')[0].numpy()\n",
    "            pred_vp2 = outputs['pred_vp2'].to('cpu')[0].numpy()\n",
    "            pred_vp3 = outputs['pred_vp3'].to('cpu')[0].numpy()\n",
    "\n",
    "            print(pred_vp1,pred_vp2,pred_vp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
